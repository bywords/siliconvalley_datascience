---
title: "Chapter 8"
author: "Kunwoo Park"
date: '2017 11 24 '
output:
  pdf_document:
    latex_engine: xelatex
mainfont: NanumGothic
---

## 8.1 분류분석이란?

주어진 입력변수에 근거하여 범주형 반응변수를 예측하는 작업

### 8.1.1 이항분류분석의 목적

(1) 미래의 데이터에 대한 정확한 예측
(2) 변수간의 관계 이해

### 8.1.2 정확도 지표, 이항편차, 혼동행렬, ROC 곡선, AUC

* 이항편차 (binomial deviance) - cross entropy?

```{r}
binomial_deviance <- function(y_obs, yhat){
  epsilon = 0.0001
  yhat = ifelse(yhat < epsilon, epsilon, yhat)
  yhat = ifelse(yhat > 1- epsilon, 1-epsilon, yhat)
  a = ifelse(y_obs==0, 0, y_obs * log(y_obs/yhat))
  b = ifelse(y_obs==1, 0, (1-y_obs) * log((1-y_obs)/(1-yhat)))
  return(2*sum(a+b))
}
```

* 혼동행렬(confusion matrix): 관측값과 예측값의 관계

* ROC curve: threshold를 변화하면서 TPR과 FPR을 그린 곡선

### 8.1.3 모형의 복잡도, 편향-분산 트레이드오프, 모형 평가, 모형 선택, 교차검증

더 많은 변수를 포함한다면... 

1. 모형의 복잡도 증가
2. 모형의 편향(bias)이 줄어듬
3. 모형의 분산이 증가: 모수 추정의 정확도가 줄어듬
4. 모형 적합에 사용된 데이터상에서 정확도 지표는 계속 개선됨 - 트레이닝 에러
5. 모형 적합에 사용되지 않은 데이터에서는 정확도 지표가 초반에는 개선되다가, 나중에는 악화됨. 즉, 과적합(overfitting)이 발생하며 이를 편향-분산 트레이드오프(bias-variance tradeoff) 라고 부름

데이터 형태의 구분
* 훈련 데이터 세트(training dataset)는 모형 내 모수의 추정에 사용
* 검증 데이터 세트(validation dataset)는 파라미터 튜닝, 변수 선택, 그리고 모형 선택에 사용
* 테스트 데이터 세트(test dataset)는 최종 모형의 오류 확률(error rate)을 추정하기 위해 사용

### 8.1.4 빅데이터, n, p, 비정형 데이터

* 빅데이터: 관측치 개수(n)가 많거나 설명변수의 숫자(p)가 큰 것을 의미함
* R에서는 n * p < 1 billion 이하라면 충분히 처리 가능
* 텍스트, 음성, 이미지, 비디오 등의 비정형 데이터는 p가 엄청 큼 - 차원 감소 필요

### 8.1.5 분류분석 문제 접근법

1. 훈련 데이터 세트(60%)로 다양한 모형을 적합
2. 검증 데이터 세트(20%)로 모형을 평가, 비교하고, 최종 모형을 선택
3. 테스트 데이터 세트(20%)로 최종 모형의 일반화 능력 계산

## 8.2 환경 준비

```{r}
install.packages(c('dplyr', 'ggplot2', 'ISLR', 'MASS', 'glmnet',
                   'randomForest', 'gbm', 'rpart', 'boot'))
library(dplyr)
library(ggplot2)
library(ISLR)
library(MASS)
library(glmnet)
library(randomForest)
library(gbm)
library(rpart)
library(boot)
```

## 8.3 분류분석 예제: 중산층 여부 예측하기

### 8.3.1 데이터 다운로드하기

```{r}
adult <- read.csv('adult.data', header=FALSE, strip.white=TRUE)
names(adult) <- c('age', 'workclass', 'fnlwgt', 'education',
                  'education_num', 'maritial_status', 'occupation',
                  'relationship', 'race', 'sex',
                  'capital_gain', 'capital_loss',
                  'hours_per_week', 'native_country',
                  'wage')

glimpse(adult)
summary(adult)
```

### 8.3.2 범주형 반응벼수의 factor 레벨

```{r}
levels(adult$wage)
```

### 8.3.3 범주형 설명변수에서 문제의 복잡도

* 범주형 설명변수의 경우 모형행렬 설정 시 복잡도가 더 큼
* 모형행렬: 수치값으로만 이루어진 행렬

```{r}
levels(adult$race)
adult$race[1:5]
levels(adult$sex)
adult$race[1:5]

x <- model.matrix( ~ race+sex+age, adult)
glimpse(x)

x_orig <- adult %>% dplyr::select(sex, race, age)
View(x_orig)

x_mod <- model.matrix( ~ sex + race + age, adult)
View(x_mod)

x <- model.matrix( ~ . - wage, adult)
dim(x)
```

## 8.4 훈련, 검증, 테스트세트의 구분

```{r}
set.seed(1601)
n <- nrow(adult)
idx <- 1:n
training_idx <- sample(idx, n* .60)
idx <- setdiff(idx, training_idx)
validate_idx <- sample(idx, n*.20)
test_idx <- setdiff(idx, validate_idx)
length(training_idx)
length(validate_idx)
length(test_idx)
training <- adult[training_idx, ]
validation <- adult[validate_idx, ]
test <- adult[test_idx, ]
```

### 8.4.1 재현가능성

* set.seed()를 이용해 동일한 분류세트를 얻을 수 있도록 함

## 8.5 시각화

```{r}
training %>%
  ggplot(aes(age, fill=wage)) +
  geom_density(alpha=.5)

training %>%
  filter(race %in% c('Black', 'White')) %>%
  ggplot(aes(age, fill=wage)) +
  geom_density(alpha=.5) +
  ylim(0, 0.1) +
  facet_grid(race ~ sex, scales = "free_y")

training %>%
  ggplot(aes(education_num, fill=wage)) +
  geom_bar()
```

## 8.6 로지스틱 회귀분석

### 8.6.1 모형 적합

```{r}
ad_glm_full <- glm(wage ~ ., data=training, family=binomial)
```

* glm.fit: fitted probabilities numerically 0 or 1 occurred 떴을 때
    1. 정규화된 모형 사용(regularized model)
    2. 모형을 변경. 변수 선택을 시도. 범주형 변수는 레벨을 줄여봄
    3. 베이지안 분석
    4. 내버려 둠. 신뢰구간은 왜곡되지만 모형 자체는 쓸만할 수 있음
    
```{r}
summary(ad_glm_full)
```

### 8.6.2 완벽한 상관 관계, collinearlity

```{r}
alias(ad_glm_full)
```

### 8.6.3 유의한 변수 살펴보기, 시각화

### 8.6.4 glm 예측, 분계점

```{r}
predict(ad_glm_full, newdata = adult[1:5, ], type="response")
```

### 8.6.5 예측 정확도 지표

```{r}
y_obs <- ifelse(validation$wage == ">50K", 1, 0)
yhat_lm <- predict(ad_glm_full, newdata=validation, type='response')

library(gridExtra)

p1 <- ggplot(data.frame(y_obs, yhat_lm),
             aes(y_obs, yhat_lm, group=y_obs,
                 fill=factor(y_obs))) +
  geom_boxplot()
p2 <- ggplot(data.frame(y_obs, yhat_lm),
             aes(yhat_lm, fill=factor(y_obs))) +
  geom_density(alpha=.5)
grid.arrange(p1, p2, ncol=2)

binomial_deviance(y_obs, yhat_lm)

library(ROCR)
pred_lm <- prediction(yhat_lm, y_obs)
perf_lm <- performance(pred_lm, measure="tpr", x.measure="fpr")
plot(perf_lm, col='black', main="ROC Curve for GLM")
abline(0, 1)
performance(pred_lm, "auc")@y.values[[1]]
```